# ğŸ§  Agentic RAG Application

An **Agentic Retrieval-Augmented Generation (RAG)** system built with:

- LangChain  
- CrewAI (Multi-Agent Orchestration)  
- FAISS (Vector Search)  
- Sentence-Transformers (Free Embeddings)  
- Tavily (Web Search)  
- Groq LLM  
- Streamlit (UI)  
- Docker (Containerized Deployment)  

---

## ğŸš€ Project Overview

This project implements a **multi-agent RAG architecture** that:

- Retrieves knowledge from a local PDF knowledge base
- Retrieves up-to-date information from the web
- Synthesizes findings using a Researcher agent
- Generates a structured report using a Writer agent
- Refines and improves the report using a Critic agent
- Displays results in a Streamlit web interface

---

## ğŸ—ï¸ System Architecture
User Question
      â†“
Retriever (FAISS + SentenceTransformer)
      â†“
Web Search (Tavily)
      â†“
Context Combination
      â†“
Researcher Agent
      â†“
Writer Agent
      â†“
Critic Agent
      â†“
Final Structured Report

---

## ğŸ§© Multi-Agent Design

### ğŸ” Researcher Agent
- Uses local RAG + web context
- Produces accurate summarized answers

### âœ Writer Agent
- Converts research summary into structured professional report

### ğŸ§ Critic Agent
- Refines clarity, coherence, and correctness
- Produces final polished output

---

## ğŸ“‚ Project Structure
project03-agentic-RAG-app/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .env
â”‚
â””â”€â”€ app/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ llm.py
    â”œâ”€â”€ vectorstore.py
    â”œâ”€â”€ tools.py
    â”œâ”€â”€ agents.py

---

## âš™ï¸ Installation (Local Development)

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv rag_env
rag_env\Scripts\activate        # Windows
source rag_env/bin/activate   # Mac/Linux

### 2ï¸âƒ£ Install Dependencies
`pip install -r requirements.txt`

### 3ï¸âƒ£ Create .env File
`GROQ_API_KEY=your_groq_key`
`TAVILY_API_KEY=your_tavily_key`
`OPENAI_API_KEY=optional`

### â–¶ï¸ Run Locally (Streamlit)
`streamlit run app.py`

- Open in browser:
`http://localhost:8501`

## ğŸ³ Docker Deployment
### 1ï¸âƒ£ Build Docker Image
`docker build -t agentic-rag-app .`

### 2ï¸âƒ£ Run Container
`docker run --env-file .env -p 8501:8501 agentic-rag-app`


- Open:
`http://localhost:8501`

## ğŸ” Environment Variables
- Variable	Description
- GROQ_API_KEY	LLM Provider
- TAVILY_API_KEY	Web Search API
- OPENAI_API_KEY	Optional (if using OpenAI embeddings)

## ğŸ§  RAG Pipeline
### Step 1 â€“ Load PDF Knowledge Base
- PyPDFLoader
- Text splitting
- Embedding with SentenceTransformer

### Step 2 â€“ Vector Store
- FAISS index built from embedded chunks

### Step 3 â€“ Retrieval
- Top relevant documents retrieved

### Step 4 â€“ Web Augmentation
- Tavily search integration

### Step 5 â€“ Context Truncation
- Token-safe trimming (prevents LLM overflow)

### Step 6 â€“ Multi-Agent Execution
- Researcher â†’ Writer â†’ Critic

##âš¡ Performance Optimizations
- âœ… Local embeddings (no paid OpenAI)
- âœ… Context truncation (~3000 chars)
- âœ… Limited web results
- âœ… Controlled agent iterations
- âœ… Cached vectorstore in Streamlit
- âœ… Docker containerized runtime

## ğŸ›  Tech Stack
- Component	Technology
- LLM	Groq (Llama 3.x)
- Embeddings	Sentence-Transformers
- Vector DB	FAISS
- Orchestration	CrewAI
- Framework	LangChain
- UI	Streamlit
- Container	Docker

## ğŸ¯ Example Questions
- What is generative AI in healthcare summarization?
- How does AI improve disease detection?
- What are risks of generative AI in healthcare?
- What is AI for health?